{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Implementation of Spatio-Temporal Graph Convolutional Networks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_timesteps_input = 12\n",
    "num_timesteps_output = 12\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "use_gpu = False\n",
    "\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_adjacent_pickle(filename):\n",
    "    \"\"\"\n",
    "    :param filename: the filename of the pickle file\n",
    "    :return: ID_mapping: the mapping from node number in CSV to [0, num_nodes]\n",
    "             A: the normalized adjacency matrix\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pk.load(f)\n",
    "    ID_mapping = data[0]\n",
    "    A = data[1]\n",
    "    return ID_mapping, A\n",
    "\n",
    "\n",
    "def load_csv(filename, ID_mapping):\n",
    "    \"\"\"\n",
    "    :param filename: the filename of the CSV file\n",
    "    :param ID_mapping: the mapping from node number in CSV to [0, num_nodes]\n",
    "    :return: data: the unnormalized np array in shape (num_nodes, num_timesteps, num_features=1)\n",
    "             num_nodes: number of nodes in graph\n",
    "             num_timesteps: number of timesteps\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    num_nodes = len(df.columns) - 1\n",
    "    num_timesteps = len(df)\n",
    "    data = [None] * num_nodes\n",
    "\n",
    "    for (col_name, col_data) in df.iteritems():\n",
    "        if col_name == \"timestamp\":\n",
    "            continue\n",
    "        node_id = ID_mapping[col_name]\n",
    "        data[node_id] = col_data.values.tolist()\n",
    "        for i in range(num_timesteps):\n",
    "            data[node_id][i] = [data[node_id][i]]\n",
    "\n",
    "    data = np.array(data)\n",
    "    return data, num_nodes, num_timesteps\n",
    "\n",
    "\n",
    "def modify_abnormal_data(unnormalized_data, num_nodes, num_timesteps):\n",
    "    \"\"\"\n",
    "    :param unnormalized_data: the unnormalized np array in shape (num_nodes, num_timesteps, num_features=1)\n",
    "    :param num_nodes: number of nodes in graph\n",
    "    :param num_timesteps: number of timesteps\n",
    "    :return: raw_data: the normalized data\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_timesteps):\n",
    "            assert len(unnormalized_data[i][j]) == 1\n",
    "            if abs(unnormalized_data[i][j][0]) <= 1e-6:\n",
    "                unnormalized_data[i][j][0] = (unnormalized_data[i][j - 1][0] + unnormalized_data[i][j + 1][0]) / 2\n",
    "\n",
    "    mean = np.mean(unnormalized_data)\n",
    "    std = np.std(unnormalized_data)\n",
    "    return unnormalized_data, mean, std\n",
    "\n",
    "\n",
    "def generate_training_data(raw_data, num_timesteps, mean, std):\n",
    "    X_train, Y_train = [], []\n",
    "\n",
    "    for time in range(num_timesteps - num_timesteps_input - num_timesteps_output + 1):\n",
    "        X_train.append(raw_data[:, time:time + num_timesteps_input])\n",
    "        Y_train.append(raw_data[:, time + num_timesteps_input:time + num_timesteps_input + num_timesteps_output])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_train = Y_train.reshape((Y_train.shape[0], Y_train.shape[1], Y_train.shape[2]))\n",
    "\n",
    "    X_train = (X_train - mean) / std\n",
    "    Y_train = (Y_train - mean) / std\n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "def generate_test_data(raw_data, mean, std):\n",
    "    X_test = []\n",
    "\n",
    "    for time in range(0, raw_data.shape[1], num_timesteps_output):\n",
    "        X_test.append(raw_data[:, time:time + num_timesteps_output])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = (X_test - mean) / std\n",
    "    return X_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ID_mapping, A = load_adjacent_pickle(\"adjacent.pkl\")\n",
    "unnormalized_data, num_nodes, num_timesteps = load_csv(\"train.csv\", ID_mapping)\n",
    "unnormalized_data, mean, std = modify_abnormal_data(unnormalized_data, num_nodes, num_timesteps)\n",
    "X_train, Y_train = generate_training_data(unnormalized_data, num_timesteps, mean, std)\n",
    "num_samples = X_train.shape[0]\n",
    "\n",
    "A = torch.from_numpy(A).double().to(device=device)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "Y_train = torch.from_numpy(Y_train)\n",
    "\n",
    "# shape of A: (num_nodes, num_nodes)\n",
    "# shape of X_train and Y_train: (num_samples, num_nodes, num_timesteps_input/output, 1)\n",
    "\n",
    "validation_split_line = int(X_train.shape[0] * 0.8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unnormalized_data, _, _ = load_csv(\"test.csv\", ID_mapping)\n",
    "X_test = generate_test_data(unnormalized_data, mean, std)\n",
    "X_test = torch.from_numpy(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Temporal_Gated_Conv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size):\n",
    "        super(Temporal_Gated_Conv, self).__init__()\n",
    "        self.output_channels = output_channels\n",
    "        self.conv = nn.Conv2d(input_channels, 2 * output_channels, (1, kernel_size))\n",
    "        self.batch_norm = nn.BatchNorm2d(num_nodes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        :param X: input data with shape (batch_size, num_nodes, num_timesteps, input_channels)\n",
    "        :return: output data with shape (batch_size, num_nodes, num_timesteps(new), output_channels)\n",
    "        \"\"\"\n",
    "        # Step 1: convert X into shape (batch_size, num_channels, num_nodes, num_timesteps)\n",
    "        X = X.permute(0, 3, 1, 2)\n",
    "        # Step 2: perform convolution, split it into P and Q\n",
    "        conv_result = self.conv(X)\n",
    "        P = conv_result[:, :self.output_channels, :, :]\n",
    "        Q = conv_result[:, self.output_channels:, :, :]\n",
    "        # Step 3: calculate result, convert it into shape (batch_size, num_nodes, num_timesteps, num_channels)\n",
    "        result = P * torch.sigmoid(Q)\n",
    "        result = result.permute(0, 2, 3, 1)\n",
    "        result = self.batch_norm(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "class ST_Conv_Block(nn.Module):\n",
    "    def __init__(self, input_channels, temporal_channels, spatio_channels, output_channels, temporal_kernel_size):\n",
    "        \"\"\"\n",
    "        :param input_channels: number of input channels\n",
    "        :param temporal_channels: number of output channels of the first temporal-gated-conv block\n",
    "        :param spatio_channels: number of output channels of the spatio graph-conv block\n",
    "        :param output_channels: number of output channels of the second temporal-gated-conv block\n",
    "        \"\"\"\n",
    "        super(ST_Conv_Block, self).__init__()\n",
    "        self.temporal_gated_conv1 = Temporal_Gated_Conv(input_channels, temporal_channels, temporal_kernel_size)\n",
    "        self.theta = nn.Parameter(torch.zeros((temporal_channels, spatio_channels), dtype=torch.float64))\n",
    "        self.temporal_gated_conv2 = Temporal_Gated_Conv(spatio_channels, output_channels, temporal_kernel_size)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_nodes)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        lim = np.sqrt(1 / self.theta.shape[1])\n",
    "        self.theta.data.uniform_(-lim, lim)\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        \"\"\"\n",
    "        :param A: the normalized spatio (n x n) matrix\n",
    "        :param X: input data with shape (batch_size, num_nodes, num_timesteps, input_channels)\n",
    "        :return: output data with shape (batch_size, num_nodes, num_timesteps, output_channels)\n",
    "        \"\"\"\n",
    "        temporal_res1 = self.temporal_gated_conv1(X)\n",
    "        mul_res1 = torch.einsum(\"mj,ijkl->imkl\", A, temporal_res1)\n",
    "        mul_res2 = torch.einsum(\"imkl,ln->imkn\", mul_res1, self.theta)\n",
    "        spatio_res = F.relu(mul_res2)\n",
    "        spatio_res = self.batch_norm(spatio_res)\n",
    "        temporal_res2 = self.temporal_gated_conv2(spatio_res)\n",
    "        return temporal_res2\n",
    "        #normalization_res = self.batch_norm(temporal_res2)\n",
    "        #return normalization_res\n",
    "\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-Temporal Graph Convolutional Network\n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps_input, num_timesteps_output, input_channels=1, temporal_kernel_size=3):\n",
    "        super(STGCN, self).__init__()\n",
    "        self.st_conv_block1 = ST_Conv_Block(input_channels=input_channels, temporal_channels=64,\n",
    "                                            spatio_channels=16, output_channels=64,\n",
    "                                            temporal_kernel_size=temporal_kernel_size)\n",
    "        self.st_conv_block2 = ST_Conv_Block(input_channels=64, temporal_channels=64,\n",
    "                                            spatio_channels=16, output_channels=64,\n",
    "                                            temporal_kernel_size=temporal_kernel_size)\n",
    "        self.temporal_gated_conv = Temporal_Gated_Conv(input_channels=64, output_channels=64,\n",
    "                                                       kernel_size=temporal_kernel_size)\n",
    "        # shape (batch_size, num_nodes, num_timesteps (- (temporal_kernel_size - 1) * (2 + 2 + 1)), 64)\n",
    "        self.fully_connected = nn.Linear((num_timesteps_input - (temporal_kernel_size - 1) * 5) * 64,\n",
    "                                         num_timesteps_output)\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        \"\"\"\n",
    "        :param A: the normalized spatio (n x n) matrix\n",
    "        :param X: input data with shape (batch_size, num_nodes, num_timesteps_input, input_channels=1)\n",
    "        :return: output data with shape (batch_size, num_nodes, num_timesteps_out)\n",
    "        \"\"\"\n",
    "        res1 = self.st_conv_block1(A, X)\n",
    "        res2 = self.st_conv_block2(A, res1)\n",
    "        res3 = self.temporal_gated_conv(res2)\n",
    "        res4 = self.fully_connected(res3.reshape((res3.shape[0], res3.shape[1], -1)))\n",
    "        return res4\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_stgcn(X_train, Y_train, batch_size=batch_size):\n",
    "    permutation = torch.randperm(X_train.shape[0])\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for t in range(0, validation_split_line, batch_size):\n",
    "        stgcn.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[t:min(t + batch_size, validation_split_line)]\n",
    "        X_batch, Y_batch = X_train[indices].to(device=device), Y_train[indices].to(device=device)\n",
    "\n",
    "        outputs = stgcn(A, X_batch)\n",
    "        loss = loss_function(outputs, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        stgcn.eval()\n",
    "\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "\n",
    "def validate_stgcn(X_train, Y_train, batch_size=batch_size):\n",
    "    permutation = torch.randperm(X_train.shape[0])[validation_split_line:]\n",
    "    X_validate = X_train[permutation]\n",
    "    Y_validate = Y_train[permutation]\n",
    "\n",
    "    losses = []\n",
    "    rmse_losses = 0\n",
    "    for t in range(0, X_validate.shape[0], batch_size):\n",
    "        with torch.no_grad():\n",
    "            stgcn.eval()\n",
    "            indices = range(t, min(t + batch_size, X_validate.shape[0]))\n",
    "            X = X_validate[indices].to(device=device)\n",
    "            Y = Y_validate[indices].to(device=device)\n",
    "            outputs = stgcn(A, X)\n",
    "            loss = loss_function(outputs, Y)\n",
    "            rmse_loss = np.sum(np.power((outputs.cpu().numpy() - Y.cpu().numpy()) * std, 2))\n",
    "            losses.append(loss.item())\n",
    "            rmse_losses += rmse_loss\n",
    "\n",
    "    return sum(losses) / len(losses), np.sqrt(rmse_losses / np.size(Y_validate.cpu().numpy()))\n",
    "\n",
    "\n",
    "def predict_stgcn(X_test, mean, std):\n",
    "    with torch.no_grad():\n",
    "        stgcn.eval()\n",
    "        X_test = X_test.to(device=device)\n",
    "        outputs = stgcn(A, X_test)\n",
    "    outputs = outputs.cpu().numpy() * std + mean\n",
    "    return outputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def output_to_csv(data):\n",
    "    assert data.shape == (200, 325, 12)\n",
    "    data = np.moveaxis(data, 1, -1)\n",
    "    assert data.shape == (200, 12, 325)\n",
    "    str_out = \"ID,Prediction\\n\"\n",
    "    cnt = 0\n",
    "    for i in range(200): # test example\n",
    "        for j in range(12): # time steps\n",
    "            for k in range(325): # node number\n",
    "                str_out += '%d,%.5f\\n' % (cnt, data[i, j, k])\n",
    "                cnt += 1\n",
    "    with open('prediction.csv', 'w') as f:\n",
    "        f.write(str_out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stgcn = STGCN(num_timesteps_input, num_timesteps_output).double().to(device=device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(stgcn.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "rmse_losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss = train_stgcn(X_train, Y_train)\n",
    "    validation_loss, rmse_loss = validate_stgcn(X_train, Y_train)\n",
    "    scheduler.step()\n",
    "\n",
    "    training_losses.append(loss)\n",
    "    validation_losses.append(validation_loss)\n",
    "    rmse_losses.append(rmse_loss)\n",
    "    print(\"epoch {}, training loss = {},\"\n",
    "          \" validation loss = {}, rmse = {}\".format(epoch, loss, validation_loss, rmse_loss))\n",
    "\n",
    "plt.plot(training_losses, label=\"Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch Num\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(rmse_losses, label=\"Validation RMSE Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch Num\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_test = predict_stgcn(X_test, mean, std)\n",
    "output_to_csv(Y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}