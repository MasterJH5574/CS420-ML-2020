{
 "cells": [
  {
   "metadata": {
    "id": "A16634FF19C74B7C876011AB5206D816",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "## 无监督学习 (Unsupervised Learning)\n",
    "\n",
    "相关算法：\n",
    "1. K-means聚类\n",
    "2. PCA主成分分析\n",
    "\n",
    "作业类型：\n",
    "1. 代码补全\n",
    "2. 简答题\n",
    "\n",
    "数据集：\n",
    "Fashion-MNIST"
   ]
  },
  {
   "metadata": {
    "id": "529DE5089EE74DCC85A7010AF0E407D0",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "### Fashion-MNIST数据集(Fashion-MNIST Dataset)\n",
    "\n",
    "来源：[A MNIST-like fashion product database](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "Fashion-MNIST数据集由[Zalando](https://jobs.zalando.com/tech/)提出，与经典的[MNIST](http://yann.lecun.com/exdb/mnist/)数据集格式完全相同：包含10个种类，总计60000张训练图片和10000张测试图片，每张图片为28\\*28尺寸的灰度图片。\n",
    "\n",
    "我们借助tensorflow的接口读取数据集文件，并实现DataLoader类用于整理数据。"
   ]
  },
  {
   "metadata": {
    "id": "0BC4C599E9074ED28E651AF02ACF9C45",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, folder):\n",
    "        self.dataset = input_data.read_data_sets(\"../input/\" + folder)\n",
    "        self.train_dataset = {}\n",
    "        self.test_dataset = {}\n",
    "        for images, labels, dataset in [(self.dataset.train.images, self.dataset.train.labels, self.train_dataset), \n",
    "                                        (self.dataset.validation.images, self.dataset.validation.labels, self.train_dataset), \n",
    "                                        (self.dataset.test.images, self.dataset.test.labels, self.test_dataset)]:\n",
    "            assert images.shape[0] == labels.shape[0]\n",
    "            for i in range(images.shape[0]):\n",
    "                if not labels[i] in dataset:\n",
    "                    dataset[labels[i]] = []\n",
    "                dataset[labels[i]].append(images[i])\n",
    "        \n",
    "    def load(self, label_list, train_n=-1, test_n=-1, shuffle=True):\n",
    "        train_list = []\n",
    "        test_list = []\n",
    "        new_label = 0\n",
    "        for label in label_list:\n",
    "            for image in self.train_dataset[label]:\n",
    "                train_list.append((image, new_label))\n",
    "            for image in self.test_dataset[label]:\n",
    "                test_list.append((image, new_label))\n",
    "            new_label += 1\n",
    "        if shuffle:\n",
    "            random.shuffle(train_list)\n",
    "            random.shuffle(test_list)\n",
    "        if train_n > 0:\n",
    "            train_list = train_list[: train_n]\n",
    "        if test_n > 0:\n",
    "            test_list = train_list[: test_n]\n",
    "        \n",
    "        return np.array([pair[0] for pair in train_list]), np.array([pair[1] for pair in train_list]), \\\n",
    "            np.array([pair[0] for pair in test_list]), np.array([pair[1] for pair in test_list]),\n",
    "                "
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "364138BD5D5F43538A09D5254F4D1ADD",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "实例化DataLoader并读取数据集文件。"
   ]
  },
  {
   "metadata": {
    "id": "8D06872F22424817AC289FFF412295C0",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "text": "WARNING:tensorflow:From <ipython-input-1-80a26b358ad4>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting ../input/Fashion_MNIST8667/train-images-idx3-ubyte.gz\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting ../input/Fashion_MNIST8667/train-labels-idx1-ubyte.gz\nExtracting ../input/Fashion_MNIST8667/t10k-images-idx3-ubyte.gz\nExtracting ../input/Fashion_MNIST8667/t10k-labels-idx1-ubyte.gz\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
     "name": "stdout"
    }
   ],
   "source": [
    "dataLoader = DataLoader(\"Fashion_MNIST8667\")"
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "A9DB942B24CA4B2DBA1629F655CEF11C",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "读取所有数据，检查数据格式，所有图片均已向量化处理。"
   ]
  },
  {
   "metadata": {
    "id": "42AD1C401FF94273B3E3E644BD444C66",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "text": "(60000, 784) (60000,)\n(10000, 784) (10000,)\n",
     "name": "stdout"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = dataLoader.load([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "91169693DBEE4B5A89275C722F2CF232",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "预览每种类别的部分图片。"
   ]
  },
  {
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 70 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/F2F9B1E01365453881B22610F8A65815/qagaqqtkcv.png\">"
     },
     "transient": {}
    }
   ],
   "execution_count": 4,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boot']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].reshape((28,28)),cmap=plt.cm.gray)\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "metadata": {
    "trusted": true,
    "collapsed": false,
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "F2F9B1E01365453881B22610F8A65815",
    "scrolled": false
   }
  },
  {
   "metadata": {
    "id": "16DC1242BC6D41B7AAFA45309B760690",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "我们选取其中的5个类别的图片进行K-means聚类学习。"
   ]
  },
  {
   "metadata": {
    "id": "586EA3ECEC104C9EAC4DED95CFDECD41",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "text": "(30000, 784) (30000,)\n(5000, 784) (5000,)\n",
     "name": "stdout"
    }
   ],
   "source": [
    "selected_classes = [0, 1, 2, 3, 4]\n",
    "n = len(selected_classes)\n",
    "\n",
    "X_train, y_train, X_test, y_test = dataLoader.load(selected_classes)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "9C854A3288224E3FB295DCA39C5C6CB2",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "### K-means聚类算法(k-means Clustering)\n",
    "\n",
    "实现最基本的K-means聚类算法。\n",
    "\n",
    "算法流程：\n",
    "1. 提供所需簇(cluster)的数量k。\n",
    "2. 随机选取k个实例作为种子节点，即作为每个簇的质心(centroid)。\n",
    "3. 迭代以下步骤：\n",
    "\t* 将每实例分配给最近质心相关联的簇。\n",
    "\t*\t重新估计每个簇的质心。\n",
    "4. 当聚类收敛时停止，或者在经过固定次数的迭代之后。\n",
    "\n",
    "**TODO：你需要补全K_Means类中fit函数的代码实现**\n",
    "\n",
    "代码解释：\n",
    "1. K_Means类中n_clusters变量为算法流程步骤1中的k，centroids为算法流程步骤2中的质心。\n",
    "2. fit函数参数列表中的max_iter为算法流程步骤4中的最大迭代次数，epsilon为收敛的阈值。\n",
    "\n",
    "要求：\n",
    "1. 实现算法流程中的所有步骤，包括质心的随机选取，迭代的收敛控制。\n",
    "2. 对fit函数的返回值没有特别要求，只需要将质心迭代结果存于centroids中，用于predict函数调用。\n",
    "3. 对质心的距离函数没有特别要求，可以尝试各种距离函数。"
   ]
  },
  {
   "metadata": {
    "id": "101DCE9A73534CDB9E53519AD6F6DB14",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, n_clusters=5):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.centroids = None\n",
    "        \n",
    "    def fit(self, X, max_iter=300, epsilon=0.01):\n",
    "        n = X.shape[0]\n",
    "        self.centroids = X[random.sample(range(n), self.n_clusters)]\n",
    "        old_pred = np.array([-1] * n)\n",
    "\n",
    "        for t in range(max_iter):\n",
    "            pred = self.predict(X)\n",
    "            if np.array_equal(pred, old_pred):\n",
    "                break\n",
    "            old_pred = pred\n",
    "            self.centroids = np.array([np.mean(X[np.where(pred == cluster)[0]], axis=0)\n",
    "                                       for cluster in range(self.n_clusters)])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.argmin(np.diag(np.dot(self.centroids - X[i], (self.centroids - X[i]).T)))\n",
    "                        for i in range(X.shape[0])])\n"
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "51C70BDD33334E59A811E448C1421761",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "在测试数据集上进行测试，并输出K-means聚类算法聚类分布。"
   ]
  },
  {
   "metadata": {
    "id": "54C16178136E4289849ABD755A15A5B8",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "text": "[[  7  33 105 305 550]\n [838  14  80  66   2]\n [  3 623  16 346  12]\n [287  20 448 235  10]\n [  8 685 156 151   0]]\n[[0.007 0.033 0.105 0.305 0.55 ]\n [0.838 0.014 0.08  0.066 0.002]\n [0.003 0.623 0.016 0.346 0.012]\n [0.287 0.02  0.448 0.235 0.01 ]\n [0.008 0.685 0.156 0.151 0.   ]]\n",
     "name": "stdout"
    }
   ],
   "source": [
    "k_means = K_Means(n_clusters=n)\n",
    "k_means.fit(X_train, max_iter=300, epsilon=0.001)\n",
    "y_predicted = k_means.predict(X_test)\n",
    "result = np.zeros((n, n), dtype=int)\n",
    "for i in range(X_test.shape[0]):\n",
    "    result[y_test[i]][y_predicted[i]] += 1\n",
    "print(result)\n",
    "result = result * 1.0\n",
    "for i in range(n):\n",
    "    result[i] /= np.sum(result[i])\n",
    "print(result)"
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "851B61CF700B42E99EED05A89D806A3C",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "通过可视化直观表现聚类的分布情况。"
   ]
  },
  {
   "metadata": {
    "id": "9CA003ADD549448E83705206C3BD750B",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/9CA003ADD549448E83705206C3BD750B/qagarbygkq.png\">"
     },
     "transient": {}
    }
   ],
   "source": [
    "plt.imshow(result)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "007B6D6A97FF417282953E0044F70A0B",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "由于K-means聚类算法属于无监督学习算法，我们无法知晓每个质心和真实分类的对应关系，没有直观的正确率概念。这里我们假设最终每个质心分别与真实分类之间是一一对应关系，并通过枚举其对应关系得到一个自定义的正确率。\n",
    "\n",
    "**最终你实现的K-means聚类算法应该达到50%的正确率。**\n",
    "\n",
    "最终的学习结果可能存在一定的波动性。\n",
    "\n",
    "**问题**：对于如何改进K-means聚类算法，例如迭代速度、稳定性、避免局部最优等方面，你有什么想法？\n",
    "**答案**：在初始的 centroids 选择阶段选第 k 个 centroid 时，与前 k - 1 个 centroids 的距离都更远的点被选为第 k 个 centroid 的概率会更大，这样可以提高算法的稳定性，避免局部最优。在每次迭代要重新计算每个点属于哪个 cluster 时，可以不用计算该点与所有 centroids 的距离，而是可以只计算其与上一轮迭代中与这个点最近的几个点的距离，这样可以加快迭代速度。\n",
    "\n",
    "**另外我发现一个问题……`K_Means` 类里的 `fit` 函数的 epsilon 似乎用不到……**"
   ]
  },
  {
   "metadata": {
    "id": "4E682BDC188540948941216537619764",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "text": "0.5734\n",
     "name": "stdout"
    }
   ],
   "source": [
    "from itertools import permutations as perm\n",
    "\n",
    "score = 0\n",
    "for p in list(perm([i for i in range(n)])):\n",
    "    s = 0\n",
    "    for k in range(n):\n",
    "        s += result[k][p[k]]\n",
    "    score = max(score, s)\n",
    "print(score / np.sum(result))"
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "112FAC422F6947799EAD4213FE758239",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "### PCA主成分分析(Principal Components Analysis)\n",
    "\n",
    "基于特征值分解协方差矩阵方法实现PCA算法。\n",
    "\n",
    "算法流程：\n",
    "1. 确定原矩阵$\\mathbf{X}_{n \\times m}$以及主成分数量k。\n",
    "2. 对$\\mathbf{X}$的每一维去中心化，即减掉各自维度的平均值。\n",
    "3. 计算协方差矩阵$\\frac{1}{n}\\mathbf{X}^T\\mathbf{X}$的特征值和特征向量。\n",
    "4. 选取k个最大的特征值对应的特征向量，组成降维投影矩阵。\n",
    "5. 对原矩阵进行降维处理并输出，维度为$n \\times k$。\n",
    "\n",
    "**TODO：你需要补全pca函数的代码实现**\n",
    "\n",
    "代码解释：\n",
    "1. pca函数参数列表中的X和k为PCA主成分分析算法流程的步骤1中的原矩阵$\\mathbf{X}_{n \\times m}$以及主成分数量k。\n",
    "\n",
    "\n",
    "要求：\n",
    "1. 可以使用numpy库中的特征值和特征向量计算函数，但不允许直接调用sklearn库中的PCA相关函数。\n",
    "2. 可以不用统一每个维度的方差。"
   ]
  },
  {
   "metadata": {
    "id": "8EA0D60DFA9C4EBD8F28635442C55234",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pca(X, k):\n",
    "    \"\"\"\n",
    "    :param X: shape (m, n) with m number of samples, n number of dimensions\n",
    "    :param k: number of principal components\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    cov = np.matmul(X.T, X) / m\n",
    "    eig_w, eig_v = np.linalg.eig(cov)\n",
    "    pc = eig_v[:, np.argsort(eig_w)[::-1][:k]]\n",
    "    projection = np.matmul(X, pc)\n",
    "    return projection"
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "460BC024A88B4193B40F28AE1F86BE7B",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "对PCA主成分分析算法的结果进行可视化处理。"
   ]
  },
  {
   "metadata": {
    "id": "4A78E713093B4F5BA9CDA8F8E1FB1D6F",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/4A78E713093B4F5BA9CDA8F8E1FB1D6F/qagardz61e.png\">"
     },
     "transient": {}
    }
   ],
   "source": [
    "X_input = np.concatenate([X_test, k_means.centroids])\n",
    "X_pca = pca(X_input, 2)\n",
    "color = ['r', 'b', 'g', 'y', 'c']\n",
    "for i in range(n):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for j in range(X_test.shape[0]):\n",
    "        if y_predicted[j] == i:\n",
    "            x_list.append(X_pca[j][0])\n",
    "            y_list.append(X_pca[j][1])\n",
    "    plt.plot(x_list, y_list, '.', color=color[i])\n",
    "    plt.plot([X_pca[- n + i][0]], [X_pca[- n + i][1]], 's', color='k')\n",
    "plt.show()"
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "id": "9EFCB5FAB1A04BCA8A19E3D3AA43FCF9",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "mdEditEnable": false,
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "与sklearn库中的PCA实现对比。\n",
    "\n",
    "**最终你实现的PCA主成分分析算法的结果应该与sklearn库的实现相似。**\n",
    "\n",
    "可能会存在旋转、缩放、镜像等差异，但拓扑关系应该保持一致。\n",
    "\n",
    "**问题**：对于PCA主成分分析算法进行数据处理的优缺点，你有什么想法？\n",
    "**答案**：\n",
    "优点：能够对数据进行降维并实现可视化，能够去除“非主成分”的噪声，算法中没有参数，没有随机性\n",
    "缺点：主成分相比起原来的维度，缺乏了解释性"
   ]
  },
  {
   "metadata": {
    "id": "56207BB1F54A4D4685E3E59B3A9BF4EA",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/56207BB1F54A4D4685E3E59B3A9BF4EA/qagarehz3w.png\">"
     },
     "transient": {}
    }
   ],
   "source": "from sklearn.decomposition import PCA\n\nX_input = np.concatenate([X_test, k_means.centroids])\nX_pca = PCA(2).fit_transform(X_input)\ncolor = ['r', 'b', 'g', 'y', 'c']\nfor i in range(n):\n    x_list = []\n    y_list = []\n    for j in range(X_test.shape[0]):\n        if y_predicted[j] == i:\n            x_list.append(X_pca[j][0])\n            y_list.append(X_pca[j][1])\n    plt.plot(x_list, y_list, '.', color=color[i])\n    plt.plot([X_pca[- n + i][0]], [X_pca[- n + i][1]], 's', color='k')\nplt.show()",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}